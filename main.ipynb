# -*- coding: utf-8 -*-
"""ML PROJECT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sxIbHkoK9wbfTbfocBwakojx6Cvdx6af
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
data = pd.read_csv('data.csv')
data.head()

import pandas as pd
import numpy as np
from google.colab import files
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

uploaded = files.upload()
data = pd.read_csv('data.csv')

print("Missing values before cleaning:\n", data.isnull().sum())

data = data.fillna(data.mean(numeric_only=True))

if 'diagnosis' in data.columns:
    label_encoder = LabelEncoder()
    data['diagnosis'] = label_encoder.fit_transform(data['diagnosis'])
else:
    raise KeyError("‚ùå 'diagnosis' column not found ‚Äî check your dataset headers!")

data = data.select_dtypes(include=[np.number])

data.to_csv('clean_data.csv', index=False)
print("\n‚úÖ Cleaned dataset saved as 'clean_data.csv'")

files.download('clean_data.csv')

if 'diagnosis' in data.columns:
    X = data.drop('diagnosis', axis=1)
    y = data['diagnosis']

    X = np.nan_to_num(X, nan=np.nanmean(X))

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    print("\n‚úÖ Data preprocessing complete!")
    print("Training set shape:", X_train.shape)
    print("Testing set shape:", X_test.shape)

from sklearn.decomposition import PCA
import numpy as np
import pandas as pd

print("Before PCA - NaN in X_train:", np.isnan(X_train).sum().sum())
print("Before PCA - NaN in X_test:", np.isnan(X_test).sum().sum())

X_train = np.nan_to_num(X_train, nan=np.nanmean(X_train))
X_test = np.nan_to_num(X_test, nan=np.nanmean(X_test))

pca = PCA(n_components=10)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

print("‚úÖ PCA completed successfully!")
print("Explained variance ratio:", pca.explained_variance_ratio_)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='rbf', random_state=42)
}

for name, model in models.items():
    model.fit(X_train_pca, y_train)
    y_pred = model.predict(X_test_pca)
    print(f"\n===== {name} =====")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis', edgecolor='k')
plt.title('PCA Feature Distribution')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report, roc_auc_score
)

uploaded = files.upload()
df = pd.read_csv('data.csv')

print("‚úÖ Dataset Loaded Successfully!")
print("Shape:", df.shape)
print("Columns:", df.columns.tolist())

df.replace(['?', 'NA', 'na', 'NaN', ' ', '--', 'null'], np.nan, inplace=True)


df.dropna(axis=1, how='all', inplace=True)

for col in df.columns:
    if df[col].dtype in ['float64', 'int64']:
        df[col].fillna(df[col].mean(), inplace=True)
    else:
        df[col].fillna(df[col].mode()[0], inplace=True)


if 'diagnosis' in df.columns:
    le = LabelEncoder()
    df['diagnosis'] = le.fit_transform(df['diagnosis'])
else:
    raise KeyError("‚ùå 'diagnosis' column not found ‚Äî check dataset headers!")


df = df.apply(pd.to_numeric, errors='coerce')
df = df.fillna(df.mean(numeric_only=True))

print("\nüîç Missing values after cleaning:\n", df.isnull().sum().sum())


X = df.drop('diagnosis', axis=1)
y = df['diagnosis']

scaler = StandardScaler()
X = scaler.fit_transform(X)

if np.isnan(X).any():
    print("‚ö†Ô∏è NaN detected after scaling ‚Äî replacing with 0")
    X = np.nan_to_num(X)

print("‚úÖ Any NaN left in X?", np.isnan(X).sum())


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)


models = {
    "SVM": SVC(kernel='rbf', probability=True, random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=7),
    "DecisionTree": DecisionTreeClassifier(max_depth=5, random_state=42),
    "NaiveBayes": GaussianNB(),
    "AdaBoost": AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42)
}

results = {}

for name, model in models.items():
    print(f"\nüöÄ Training {name} model...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    acc = accuracy_score(y_test, y_pred)
    roc = roc_auc_score(y_test, y_prob) if y_prob is not None else None

    results[name] = {"Accuracy": acc, "ROC_AUC": roc}

    print(f"\nüìä {name} Results")
    print("Accuracy:", round(acc, 4))
    if roc:
        print("ROC-AUC:", round(roc, 4))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))


results_df = pd.DataFrame(results).T
print("\nüèÅ Model Performance Summary:")
print(results_df)

plt.figure(figsize=(8, 5))
sns.barplot(x=results_df.index, y=results_df['Accuracy'])
plt.title("Model Accuracy Comparison (Breast Cancer Dataset)")
plt.ylabel("Accuracy")
plt.xlabel("Model")
plt.ylim(0, 1)
plt.show()


plt.figure(figsize=(15, 8))
for i, (name, model) in enumerate(models.items()):
    plt.subplot(2, 3, i + 1)
    y_pred = model.predict(X_test)
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
plt.tight_layout()
plt.show()
